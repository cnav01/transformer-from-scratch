{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6722a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e96aa02",
   "metadata": {},
   "source": [
    "### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97fb6962",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4 # Eg: \"My name is Nav\"\n",
    "batch_size = 1\n",
    "input_dim = 512 # Embedding dimension\n",
    "d_model = 512\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a726a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78a5ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim, 3 * d_model) # For Q, K, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5956aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = qkv_layer(x) # passing I/P to the layer to generate Q, K, v vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa45bd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "535eb791",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3*head_dim) # splitting into 8 heads, with each having (qkv) -> 192 dim (where q - 64, k - 64, v - 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "009f605f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d170fccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interchanging sequence_length and num_heads for ease of calculation\n",
    "qkv = qkv.permute(0, 2, 1, 3) # (batch_size, num_heads, sequence_length, 3*head_dim)\n",
    "qkv.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd06f9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = torch.chunk(qkv, 3, dim=-1) # splitting last dim into 3 parts\n",
    "q.size(), k.size(), v.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4087ca",
   "metadata": {},
   "source": [
    "### Self Attention for multi-heads\n",
    "\n",
    "self attention = softmax(Q.K^T/sqrt(d_k) + M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23d13765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "scaled.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9c2fd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# masking\n",
    "mask = torch.full(scaled.size(), float('-inf'))\n",
    "mask = torch.triu(mask, diagonal=1) # upper triangular matrix\n",
    "mask[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08d4471c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2947,    -inf,    -inf,    -inf],\n",
       "        [ 0.4688,  0.0434,    -inf,    -inf],\n",
       "        [ 0.1908, -0.1342,  0.0264,    -inf],\n",
       "        [ 0.1232,  0.4566, -0.5165, -0.1695]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "948da608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled+= mask\n",
    "scaled.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd973738",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab014baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]\n",
    "attention.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4116c4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention, v) # new value vectors are more context aware than v\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9a702c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return values and attention\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7bf2d",
   "metadata": {},
   "source": [
    "### Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "163f111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 10\n",
    "d_model = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0460d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_i = torch.arange(0, d_model, 2).float()  # even indices\n",
    "even_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19508090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_denominator = torch.pow(10000, even_i/d_model)\n",
    "even_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf258bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 3., 5.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_i = torch.arange(1, d_model, 2).float()  # odd indices\n",
    "odd_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc271cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_denominator = torch.pow(10000, (odd_i-1)/d_model)\n",
    "odd_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9448e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even and odd denominators are the same\n",
    "denominator = even_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d49583c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = torch.arange(max_sequence_length, dtype=torch.float).reshape(max_sequence_length, 1)\n",
    "position.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc237de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denominator.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad31bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_PE = torch.sin(position / denominator)\n",
    "odd_PE = torch.cos(position / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90b0421f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.8415,  0.0464,  0.0022],\n",
       "        [ 0.9093,  0.0927,  0.0043],\n",
       "        [ 0.1411,  0.1388,  0.0065],\n",
       "        [-0.7568,  0.1846,  0.0086],\n",
       "        [-0.9589,  0.2300,  0.0108],\n",
       "        [-0.2794,  0.2749,  0.0129],\n",
       "        [ 0.6570,  0.3192,  0.0151],\n",
       "        [ 0.9894,  0.3629,  0.0172],\n",
       "        [ 0.4121,  0.4057,  0.0194]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf9f34f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000],\n",
       "        [ 0.5403,  0.9989,  1.0000],\n",
       "        [-0.4161,  0.9957,  1.0000],\n",
       "        [-0.9900,  0.9903,  1.0000],\n",
       "        [-0.6536,  0.9828,  1.0000],\n",
       "        [ 0.2837,  0.9732,  0.9999],\n",
       "        [ 0.9602,  0.9615,  0.9999],\n",
       "        [ 0.7539,  0.9477,  0.9999],\n",
       "        [-0.1455,  0.9318,  0.9999],\n",
       "        [-0.9111,  0.9140,  0.9998]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_PE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d7edf4",
   "metadata": {},
   "source": [
    "### Interleaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c011d641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked  = torch.stack( [even_PE, odd_PE], dim=2)\n",
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e097463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
       "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
       "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
       "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
       "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
       "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
       "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
       "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
       "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE = stacked.reshape(max_sequence_length, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd374e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
       "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
       "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
       "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
       "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
       "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
       "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
       "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
       "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self):\n",
    "        even_i = torch.arange(0, self.d_model, 2).float()  # even indices\n",
    "        denominator = torch.pow(10000, even_i/self.d_model)\n",
    "        position = torch.arange(self.max_sequence_length).float().reshape(self.max_sequence_length, 1)\n",
    "        even_PE = torch.sin(position / denominator)\n",
    "        odd_PE = torch.cos(position / denominator)\n",
    "        stacked = torch.stack( [even_PE, odd_PE], dim=2)\n",
    "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "        return PE\n",
    "    \n",
    "pos_enc = PositionalEncoding(d_model=6, max_sequence_length=10)\n",
    "pos_enc.forward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc781fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79ffdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
